{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/bluewall/spotting-mental-health-markers-on-social-media?scriptVersionId=143312610\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\n\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('stopwords')\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport time\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"slg0KzGiFUyx","outputId":"efd7e913-7449-4e28-84ec-0dd8dc71fdf9","execution":{"iopub.status.busy":"2023-09-17T14:58:26.588222Z","iopub.execute_input":"2023-09-17T14:58:26.588531Z","iopub.status.idle":"2023-09-17T14:58:29.682052Z","shell.execute_reply.started":"2023-09-17T14:58:26.588501Z","shell.execute_reply":"2023-09-17T14:58:29.681029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"bTFFKS_XFsnV","execution":{"iopub.status.busy":"2023-09-17T14:58:32.818191Z","iopub.execute_input":"2023-09-17T14:58:32.818699Z","iopub.status.idle":"2023-09-17T14:58:32.823316Z","shell.execute_reply.started":"2023-09-17T14:58:32.818664Z","shell.execute_reply":"2023-09-17T14:58:32.822329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{"id":"oId-_aY8FUyy"}},{"cell_type":"code","source":"#load the dataset\ndata=pd.read_csv('/kaggle/input/suicide-watch/Suicide_Detection.csv')\ndata.head()","metadata":{"id":"aYmogQzaFUyz","outputId":"f9c8a1a9-9a8c-4d8e-9633-1cd93e776757","execution":{"iopub.status.busy":"2023-09-17T14:59:30.356414Z","iopub.execute_input":"2023-09-17T14:59:30.356784Z","iopub.status.idle":"2023-09-17T14:59:34.49506Z","shell.execute_reply.started":"2023-09-17T14:59:30.356754Z","shell.execute_reply":"2023-09-17T14:59:34.494044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Size of the dataframe\ndata.shape","metadata":{"id":"ovPBQKkXFUy0","outputId":"2533775e-1e71-4e1a-9112-d6f6f96d1db5","execution":{"iopub.status.busy":"2023-09-17T14:59:35.755199Z","iopub.execute_input":"2023-09-17T14:59:35.755556Z","iopub.status.idle":"2023-09-17T14:59:35.762794Z","shell.execute_reply.started":"2023-09-17T14:59:35.755518Z","shell.execute_reply":"2023-09-17T14:59:35.761646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Rename Unamed column\n\ndata = data.rename(columns={'Unnamed: 0':'ID'})","metadata":{"id":"VCdRK9eMFUy0","execution":{"iopub.status.busy":"2023-09-17T14:59:36.721332Z","iopub.execute_input":"2023-09-17T14:59:36.721713Z","iopub.status.idle":"2023-09-17T14:59:36.735309Z","shell.execute_reply.started":"2023-09-17T14:59:36.721683Z","shell.execute_reply":"2023-09-17T14:59:36.734416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Unique values in class\nprint(data['class'].unique())","metadata":{"id":"msYAl4v_FUy0","outputId":"e6a65bf9-fb4b-4d65-c647-b9083334824b","execution":{"iopub.status.busy":"2023-09-17T14:59:37.537706Z","iopub.execute_input":"2023-09-17T14:59:37.538782Z","iopub.status.idle":"2023-09-17T14:59:37.568372Z","shell.execute_reply.started":"2023-09-17T14:59:37.538743Z","shell.execute_reply":"2023-09-17T14:59:37.567283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create binary for class column\ndata['class_binary'] = data['class'].map({'suicide': 1, 'non-suicide': 0})","metadata":{"id":"1hCd0jJ0FUy0","execution":{"iopub.status.busy":"2023-09-17T14:59:38.175652Z","iopub.execute_input":"2023-09-17T14:59:38.176351Z","iopub.status.idle":"2023-09-17T14:59:38.213392Z","shell.execute_reply.started":"2023-09-17T14:59:38.176309Z","shell.execute_reply":"2023-09-17T14:59:38.212448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dropna()","metadata":{"id":"Or09C93rFUy0","outputId":"af2fcc47-660d-47f3-d8d5-51be38b7f13d","execution":{"iopub.status.busy":"2023-09-17T14:59:38.73252Z","iopub.execute_input":"2023-09-17T14:59:38.732906Z","iopub.status.idle":"2023-09-17T14:59:38.82213Z","shell.execute_reply.started":"2023-09-17T14:59:38.732879Z","shell.execute_reply":"2023-09-17T14:59:38.821216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Text Preprocessing","metadata":{"id":"3buDOjPiFUy0"}},{"cell_type":"code","source":"\nstop_words = set(stopwords.words('english'))\n\ndef preprocess_text(text):\n    #remove urls\n    text = re.sub(r'http\\S+', '', text)\n    #remove number and punctuation\n    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n    #remove stopwords\n    text = ' '.join(word for word in text.split() if word not in stop_words)\n\n    return text\n\ndata['processed_text'] = data['text'].apply(preprocess_text)\n\n\n\ndata.head()","metadata":{"id":"ldCIcRHxFUy1","outputId":"4cae81de-ac69-4a35-bb7d-0b4968dcc108","execution":{"iopub.status.busy":"2023-09-17T14:59:40.307751Z","iopub.execute_input":"2023-09-17T14:59:40.308118Z","iopub.status.idle":"2023-09-17T14:59:53.612427Z","shell.execute_reply.started":"2023-09-17T14:59:40.30809Z","shell.execute_reply":"2023-09-17T14:59:53.611482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extraction","metadata":{"id":"7wtYyJybFUy1"}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(max_features = 5000) #Limiting to 5000 most frequent words for simplicity\nX = vectorizer.fit_transform(data['processed_text'])\ny = data['class']\nz = data['class_binary'] #z_train, z_test\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","metadata":{"id":"P6FRmzd_FUy1","execution":{"iopub.status.busy":"2023-09-17T14:59:53.614389Z","iopub.execute_input":"2023-09-17T14:59:53.615066Z","iopub.status.idle":"2023-09-17T15:00:13.160564Z","shell.execute_reply.started":"2023-09-17T14:59:53.615033Z","shell.execute_reply":"2023-09-17T15:00:13.15959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model and Evaluate","metadata":{"id":"3-fu_VVwFUy1"}},{"cell_type":"code","source":"clf = MultinomialNB()\nclf.fit(X_train, y_train)\n\ny_pred = clf.predict(X_test)\n\nprint(classification_report(y_test, y_pred))","metadata":{"id":"zxW0b8iBFUy1","outputId":"5e213b2e-838a-477b-da0c-f8c45b90972f","execution":{"iopub.status.busy":"2023-09-17T15:00:13.16198Z","iopub.execute_input":"2023-09-17T15:00:13.162435Z","iopub.status.idle":"2023-09-17T15:00:16.738353Z","shell.execute_reply.started":"2023-09-17T15:00:13.162401Z","shell.execute_reply":"2023-09-17T15:00:16.737381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizations","metadata":{"id":"_RjoNBiPFUy2"}},{"cell_type":"markdown","source":"## Confusion Matrix","metadata":{"id":"D0S6LkL-FUy2"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"id":"lOukSGGMFUy2","outputId":"e26d3c72-1aeb-42a6-be26-3153778b5adc","execution":{"iopub.status.busy":"2023-09-17T15:00:16.74111Z","iopub.execute_input":"2023-09-17T15:00:16.741472Z","iopub.status.idle":"2023-09-17T15:00:17.340703Z","shell.execute_reply.started":"2023-09-17T15:00:16.741439Z","shell.execute_reply":"2023-09-17T15:00:17.339826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Class Distribution Bar Chart","metadata":{"id":"l-qW1dxgFUy2"}},{"cell_type":"code","source":"sns.countplot(data=data, x='class')\nplt.title('Class Distribution')\nplt.show()","metadata":{"id":"70RLhwnZFUy2","outputId":"a76f3150-152f-434c-c0ae-f1b6bc396640","execution":{"iopub.status.busy":"2023-09-17T15:00:17.343484Z","iopub.execute_input":"2023-09-17T15:00:17.343797Z","iopub.status.idle":"2023-09-17T15:00:17.785166Z","shell.execute_reply.started":"2023-09-17T15:00:17.343772Z","shell.execute_reply":"2023-09-17T15:00:17.784258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Word Cloud","metadata":{"id":"4Z9RDKioFUy2"}},{"cell_type":"code","source":"from wordcloud import WordCloud\n\nall_text = ' '.join(data['processed_text'])\nwordcloud = WordCloud(background_color='white', width=800, height=800).generate(all_text)\n\nplt.figure(figsize=(10, 10))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.show()","metadata":{"id":"wW0eqfP4FUy2","outputId":"79ee6fcf-8018-4545-c64a-6ef0c0d9e721","execution":{"iopub.status.busy":"2023-09-17T15:00:17.786554Z","iopub.execute_input":"2023-09-17T15:00:17.78691Z","iopub.status.idle":"2023-09-17T15:01:55.577126Z","shell.execute_reply.started":"2023-09-17T15:00:17.786879Z","shell.execute_reply":"2023-09-17T15:01:55.576122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction for Precision-Recall","metadata":{"id":"iagrfIxLFUy2"}},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(max_features = 5000) #Limiting to 5000 most frequent words for simplicity\nX = vectorizer.fit_transform(data['processed_text'])\ny = data['class_binary']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","metadata":{"id":"nv7pFw67FUy2","execution":{"iopub.status.busy":"2023-09-17T15:01:55.578081Z","iopub.execute_input":"2023-09-17T15:01:55.578389Z","iopub.status.idle":"2023-09-17T15:02:13.004675Z","shell.execute_reply.started":"2023-09-17T15:01:55.578363Z","shell.execute_reply":"2023-09-17T15:02:13.003643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Precision-Recall Curve","metadata":{"id":"Fl3MX0zaFUy3"}},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\n\nprecision, recall, _ = precision_recall_curve(y_test, clf.predict_proba(X_test)[:,1])\n\nplt.figure()\nplt.plot(recall, precision, color='darkorange', lw=2)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.show()\n","metadata":{"id":"tnhnmWTMFUy3","outputId":"65826c61-3813-405e-948b-cdb2e13b7043","execution":{"iopub.status.busy":"2023-09-17T15:02:13.006278Z","iopub.execute_input":"2023-09-17T15:02:13.006679Z","iopub.status.idle":"2023-09-17T15:02:13.286866Z","shell.execute_reply.started":"2023-09-17T15:02:13.006646Z","shell.execute_reply":"2023-09-17T15:02:13.285936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Extraction for Roc Curve AUC","metadata":{"id":"0YJVNUTKFUy3"}},{"cell_type":"markdown","source":"### Roc Curve and AUC is a little stubborn on any platform\n### There is a need to try different techniques","metadata":{"id":"P-EiNRp3FUy3"}},{"cell_type":"markdown","source":"### This is extremely slow and costly.","metadata":{"id":"eN1IqL73RJ1y"}},{"cell_type":"code","source":"\n####clf = RandomForestClassifier()\n####clf.fit(X_train, y_train)\n\n# ROC Curve and AUC\n####fpr, tpr, thresholds = roc_curve(y_test, clf.predict_proba(X_test)[:, 1])\n####roc_auc = auc(fpr, tpr)","metadata":{"id":"oao4j3D0FUy3","execution":{"iopub.status.busy":"2023-09-17T15:02:13.288267Z","iopub.execute_input":"2023-09-17T15:02:13.28861Z","iopub.status.idle":"2023-09-17T15:02:13.293424Z","shell.execute_reply.started":"2023-09-17T15:02:13.288562Z","shell.execute_reply":"2023-09-17T15:02:13.292522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### With a bit of research I found chunking, joblib","metadata":{"id":"Wtgp38_Gc8Gj"}},{"cell_type":"code","source":"\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc\nfrom sklearn.linear_model import LogisticRegression\nfrom joblib import Parallel, delayed","metadata":{"id":"gbWFK8VPFUy3","execution":{"iopub.status.busy":"2023-09-17T15:02:13.296861Z","iopub.execute_input":"2023-09-17T15:02:13.297432Z","iopub.status.idle":"2023-09-17T15:02:13.303508Z","shell.execute_reply.started":"2023-09-17T15:02:13.297399Z","shell.execute_reply":"2023-09-17T15:02:13.302448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chunk_size = 1000\n\n# Calculate the number of chunks required\nnum_chunks = len(data) // chunk_size + 1\n\n# Create a list of DataFrame chunks\ndata_chunks = [data[i * chunk_size:(i + 1) * chunk_size] for i in range(num_chunks)]\n\ndef calculate_roc_chunk(chunk):\n    # Extract text and labels\n    text_chunk = chunk['processed_text']\n    labels_chunk = chunk['class_binary'].values  # Assuming 'class' column is binary-encoded (0 or 1)\n\n    # Vectorize the text data\n    X_chunk =  vectorizer.fit_transform(text_chunk)\n\n    # Split data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X_chunk, labels_chunk, test_size=0.2, random_state=42)\n\n    # Train a binary classification model\n    model = LogisticRegression(max_iter=1000)\n    model.fit(X_train, y_train)\n\n    # Predict probabilities for the positive class\n    y_prob = model.predict_proba(X_test)[:, 1]\n\n    # Calculate ROC curve for this chunk\n    fpr, tpr, _ = roc_curve(y_test, y_prob)\n\n    return y_test, y_prob  # Return y_test and y_prob\n\n# Parallelize the ROC curve calculation for each chunk\nroc_curves = Parallel(n_jobs=-1)(\n    delayed(calculate_roc_chunk)(chunk) for chunk in data_chunks\n)\n\n# Now, 'roc_curves' is a list of (y_test, y_prob) pairs for each chunk\n\n# Calculate ROC AUC for each chunk\nroc_aucs = [roc_auc_score(y_test, y_prob) for y_test, y_prob in roc_curves]\n\n# Calculate overall ROC AUC by aggregating individual AUCs\noverall_roc_auc = sum(roc_aucs) / len(roc_aucs)\n\nprint(f\"Overall ROC AUC: {overall_roc_auc}\")","metadata":{"id":"a_aaMFl3RV6C","outputId":"050368b6-beac-4a31-dafd-e51d3b6c5a38","execution":{"iopub.status.busy":"2023-09-17T15:02:13.305727Z","iopub.execute_input":"2023-09-17T15:02:13.306011Z","iopub.status.idle":"2023-09-17T15:03:05.188281Z","shell.execute_reply.started":"2023-09-17T15:02:13.305989Z","shell.execute_reply":"2023-09-17T15:03:05.186572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_roc_chunk(chunk):\n    # Extract text and labels\n    text_chunk = chunk['processed_text']\n    labels_chunk = chunk['class_binary'].values\n\n    # Vectorize the text data (\n    X_chunk =  vectorizer.fit_transform(text_chunk)\n\n    # Split data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X_chunk, labels_chunk, test_size=0.2, random_state=42)\n\n    # Train a binary classification model (e.g., Logistic Regression)\n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n\n    # Predict probabilities for the positive class\n    y_prob = model.predict_proba(X_test)[:, 1]\n\n    # Calculate ROC curve for this chunk\n    fpr, tpr, _ = roc_curve(y_test, y_prob)\n\n    return fpr, tpr  # Return fpr and tpr\n\n# Parallelize the ROC curve calculation for each chunk\nstart_time = time.time()\nroc_curves = Parallel(n_jobs=-1)(\n    delayed(calculate_roc_chunk)(chunk) for chunk in data_chunks\n)\nend_time = time.time()\nexecution_time = end_time-start_time\n\nprint(f\"Execution Time: {execution_time: .2f} seconds\")\n\n# Now, 'roc_curves' is a list of (fpr, tpr) pairs for each chunk\n\n# Create an empty list to store AUC values\nroc_aucs = []\n\n# Initialize a figure for the ROC curve plot\nplt.figure(figsize=(8, 6))\n\n# Plot ROC curves for each chunk and calculate ROC AUC values\nfor fpr, tpr in roc_curves:\n    roc_auc = auc(fpr, tpr)\n    roc_aucs.append(roc_auc)\n    plt.plot(fpr, tpr, lw=2)\n\n# Calculate overall ROC AUC by aggregating individual AUCs\noverall_roc_auc = np.mean(roc_aucs)\n\n# Plot the diagonal line (random classifier)\nplt.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=2)\n\n# Customize the plot\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title(f'ROC Curve (Overall AUC = {overall_roc_auc:.2f})')\n#plt.legend([f'Chunk {i+1}' for i in range(len(roc_curves))] + ['Random'], loc='lower right')\nplt.show()","metadata":{"id":"jdb-jqfYTqnC","outputId":"ccfc6179-d6fa-4092-d324-ca4af1ec302a","execution":{"iopub.status.busy":"2023-09-17T15:03:05.190143Z","iopub.execute_input":"2023-09-17T15:03:05.190504Z","iopub.status.idle":"2023-09-17T15:03:55.833577Z","shell.execute_reply.started":"2023-09-17T15:03:05.190469Z","shell.execute_reply":"2023-09-17T15:03:55.832499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Multiprocessing","metadata":{"id":"7HiZQIrweZNq"}},{"cell_type":"code","source":"from multiprocessing import Pool","metadata":{"id":"ayU6bcD8eUVq","execution":{"iopub.status.busy":"2023-09-17T15:03:55.835191Z","iopub.execute_input":"2023-09-17T15:03:55.835566Z","iopub.status.idle":"2023-09-17T15:03:55.840479Z","shell.execute_reply.started":"2023-09-17T15:03:55.835522Z","shell.execute_reply":"2023-09-17T15:03:55.839324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define a function to calculate ROC curves for a chunk of data\ndef calculate_roc_chunk(chunk):\n    # Extract text and labels\n    text_chunk = chunk['processed_text']\n    labels_chunk = chunk['class_binary'].values\n\n    # Vectorize the text data\n    X_chunk = vectorizer.transform(text_chunk)\n\n    # Split data into train and test sets\n    X_train, X_test, y_train, y_test = train_test_split(X_chunk, labels_chunk, test_size=0.2, random_state=42)\n\n    # Train a binary classification model\n    model = LogisticRegression(max_iter=1000)\n    model.fit(X_train, y_train)\n\n    # Predict probabilities for the positive class\n    y_prob = model.predict_proba(X_test)[:, 1]\n\n    # Calculate ROC curve for this chunk\n    fpr, tpr, _ = roc_curve(y_test, y_prob)\n\n    return fpr, tpr  # Return fpr and tpr\n\n# Create a Pool of worker processes\n\nnum_processes = 4\nstart_time = time.time()\nwith Pool(num_processes) as pool:\n    # Parallelize the ROC curve calculation for each chunk\n    roc_curves = pool.map(calculate_roc_chunk, data_chunks)\n\nend_time = time.time()\nexecution_time = end_time-start_time\n\nprint(f\"Execution Time: {execution_time: .2f} seconds\")\n\n\n\n# Create an empty list to store AUC values\nroc_aucs = []\n\n# Initialize a figure for the ROC curve plot\nplt.figure(figsize=(8, 6))\n\n# Plot ROC curves for each chunk and calculate ROC AUC values\nfor fpr, tpr in roc_curves:\n    roc_auc = auc(fpr, tpr)  # Calculate AUC for each chunk\n    roc_aucs.append(roc_auc)\n    plt.plot(fpr, tpr, lw=2)\n\n# Calculate overall ROC AUC by aggregating individual AUCs\noverall_roc_auc = np.mean(roc_aucs)\n\n# Plot the diagonal line\nplt.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=2)\n\n# Customize the plot\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title(f'ROC Curve (Overall AUC = {overall_roc_auc:.2f})')\n#plt.legend([f'Chunk {i+1}' for i in range(len(roc_curves))] + ['Random'], loc='lower right')\nplt.show()","metadata":{"id":"0Qwb_BG1eviz","outputId":"b8778a0a-dc28-4f9a-8ac1-8b3b40f3834f","execution":{"iopub.status.busy":"2023-09-17T15:03:55.842279Z","iopub.execute_input":"2023-09-17T15:03:55.843006Z","iopub.status.idle":"2023-09-17T15:04:18.26156Z","shell.execute_reply.started":"2023-09-17T15:03:55.842972Z","shell.execute_reply":"2023-09-17T15:04:18.260511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"4LOBddraj3So"},"execution_count":null,"outputs":[]}]}